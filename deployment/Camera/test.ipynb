{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427622273753\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "RealSense Camera.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import time\n",
    "\n",
    "def get_realsense_serials():\n",
    "    '''\n",
    "    Get the serial numbers of the connected RealSense cameras.\n",
    "    '''\n",
    "    context = rs.context()\n",
    "    devices = context.query_devices()\n",
    "    serials = [device.get_info(rs.camera_info.serial_number) for device in devices]\n",
    "    return serials\n",
    "\n",
    "class RealSenseRGBDCamera:\n",
    "    '''\n",
    "    RealSense RGB-D Camera.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self, \n",
    "        serial, \n",
    "        frame_rate = 30, \n",
    "        resolution = (1280, 720),\n",
    "        align = True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        '''\n",
    "        Initialization.\n",
    "\n",
    "        Parameters:\n",
    "        - serial: str, required, the serial number of the realsense device;\n",
    "        - frame_rate: int, optional, default: 15, the framerate of the realsense camera;\n",
    "        - resolution: (int, int), optional, default: (1280, 720), the resolution of the realsense camera;\n",
    "        - align: bool, optional, default: True, whether align the frameset with the RGB image.\n",
    "        '''\n",
    "        super(RealSenseRGBDCamera, self).__init__()\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.serial = serial\n",
    "        # =============== Support L515 Camera ============== #\n",
    "        self.is_radar = str.isalpha(serial[0])\n",
    "        depth_resolution = (1024, 768) if self.is_radar else resolution\n",
    "        if self.is_radar:\n",
    "            frame_rate = max(frame_rate, 30)\n",
    "            self.depth_scale = 4000\n",
    "        else:\n",
    "            self.depth_scale = 1000\n",
    "        # ================================================== #\n",
    "        self.config.enable_device(self.serial)\n",
    "        self.config.enable_stream(rs.stream.depth, depth_resolution[0], depth_resolution[1], rs.format.z16, frame_rate)\n",
    "        self.config.enable_stream(rs.stream.color, resolution[0], resolution[1], rs.format.rgb8, frame_rate)\n",
    "        self.pipeline.start(self.config)\n",
    "        self.align_to = rs.stream.color\n",
    "        self.align = rs.align(self.align_to)\n",
    "        self.with_align = align\n",
    "\n",
    "    def get_rgb_image(self):\n",
    "        '''\n",
    "        Get the RGB image from the camera.\n",
    "        '''\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        color_image = np.asanyarray(color_frame.get_data()).astype(np.uint8)\n",
    "        return color_image\n",
    "\n",
    "    def get_depth_image(self):\n",
    "        '''\n",
    "        Get the depth image from the camera.\n",
    "        '''\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "        depth_image = np.asanyarray(depth_frame.get_data()).astype(np.float32) / self.depth_scale\n",
    "        return depth_image\n",
    "\n",
    "    def get_rgbd_image(self):\n",
    "        '''\n",
    "        Get the RGB image along with the depth image from the camera.\n",
    "        '''\n",
    "        frameset = self.pipeline.wait_for_frames()\n",
    "        if self.with_align:\n",
    "            frameset = self.align.process(frameset)\n",
    "        color_image = np.asanyarray(frameset.get_color_frame().get_data()).astype(np.uint8)\n",
    "        depth_image = np.asanyarray(frameset.get_depth_frame().get_data()).astype(np.float32) / self.depth_scale\n",
    "        return color_image, depth_image\n",
    "    \n",
    "\n",
    "serial = get_realsense_serials()[0]\n",
    "print(serial)\n",
    "camera = RealSenseRGBDCamera('427622273753')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consume time: 0.0030717849731445312\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "color, depth = camera.get_rgbd_image()  # 这样调用一次耗时0.004s左右\n",
    "end_time = time.time()\n",
    "print(\"consume time:\", end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 devices: ['427622273753']\n",
      "front camera start.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing camera 427622273753\n",
      "-------<pyrealsense2.device: D405 (S/N: 427622273753  FW: 5.12.14.100  on USB3.2)>-------\n",
      "camera <pyrealsense2.device: D405 (S/N: 427622273753  FW: 5.12.14.100  on USB3.2)> init.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque \n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import pyrealsense2 as rs\n",
    "from multiprocessing import Process, Pipe, Queue, Event\n",
    "import time\n",
    "import multiprocessing\n",
    "from PIL import Image\n",
    "# multiprocessing.set_start_method('fork')\n",
    "\n",
    "np.printoptions(3, suppress=True)\n",
    "\n",
    "def get_realsense_id():\n",
    "    ctx = rs.context()\n",
    "    devices = ctx.query_devices()\n",
    "    devices = [devices[i].get_info(rs.camera_info.serial_number) for i in range(len(devices))]\n",
    "    devices.sort() # Make sure the order is correct\n",
    "    print(\"Found {} devices: {}\".format(len(devices), devices))\n",
    "    return devices\n",
    "\n",
    "def init_given_realsense(\n",
    "    device,\n",
    "    enable_rgb=True,\n",
    "    enable_depth=False,\n",
    "    enable_point_cloud=False,\n",
    "    sync_mode=0,\n",
    "):\n",
    "    # use `rs-enumerate-devices` to check available resolutions\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_device(device)\n",
    "    print(\"Initializing camera {}\".format(device))\n",
    "\n",
    "    if enable_depth:\n",
    "        # Depth         1024x768      @ 30Hz     Z16\n",
    "        # Depth         640x480       @ 30Hz     Z16\n",
    "        # Depth         320x240       @ 30Hz     Z16\n",
    "        # h, w = 768, 1024\n",
    "        h, w = 480, 640\n",
    "        config.enable_stream(rs.stream.depth, w, h, rs.format.z16, 30)\n",
    "    if enable_rgb:\n",
    "        # h, w = 540, 960\n",
    "        h, w = 480, 640\n",
    "        config.enable_stream(rs.stream.color, w, h, rs.format.rgb8, 30)\n",
    "\n",
    "    config.resolve(pipeline)\n",
    "    profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "    if enable_depth:\n",
    "\n",
    "        # Get the depth sensor (or any other sensor you want to configure)\n",
    "        device = profile.get_device()\n",
    "        print(f\"-------{device}-------\")\n",
    "        depth_sensor = device.query_sensors()[0]\n",
    "\n",
    "        # Set the inter-camera sync mode\n",
    "        # Use 1 for master, 2 for slave, 0 for default (no sync)\n",
    "        # depth_sensor.set_option(rs.option.inter_cam_sync_mode, sync_mode)\n",
    "        \n",
    "        # set min distance\n",
    "        # depth_sensor.set_option(rs.option.min_distance, 0.05)\n",
    "        \n",
    "        # get depth scale\n",
    "        depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "        align = rs.align(rs.stream.color)\n",
    "        \n",
    "        depth_profile = profile.get_stream(rs.stream.depth)\n",
    "        intrinsics = depth_profile.as_video_stream_profile().get_intrinsics()\n",
    "        camera_info = CameraInfo(intrinsics.width, intrinsics.height, intrinsics.fx, intrinsics.fy, intrinsics.ppx, intrinsics.ppy)\n",
    "        \n",
    "        print(\"camera {} init.\".format(device))\n",
    "        return pipeline, align, depth_scale, camera_info\n",
    "    else:\n",
    "        print(\"camera {} init.\".format(device))\n",
    "        return pipeline, None, None, None\n",
    "\n",
    "\n",
    "def grid_sample_pcd(point_cloud, grid_size=0.005):\n",
    "    \"\"\"\n",
    "    A simple grid sampling function for point clouds.\n",
    "\n",
    "    Parameters:\n",
    "    - point_cloud: A NumPy array of shape (N, 3) or (N, 6), where N is the number of points.\n",
    "                   The first 3 columns represent the coordinates (x, y, z).\n",
    "                   The next 3 columns (if present) can represent additional attributes like color or normals.\n",
    "    - grid_size: Size of the grid for sampling.\n",
    "\n",
    "    Returns:\n",
    "    - A NumPy array of sampled points with the same shape as the input but with fewer rows.\n",
    "    \"\"\"\n",
    "    coords = point_cloud[:, :3]  # Extract coordinates\n",
    "    scaled_coords = coords / grid_size\n",
    "    grid_coords = np.floor(scaled_coords).astype(int)\n",
    "    \n",
    "    # Create unique grid keys\n",
    "    keys = grid_coords[:, 0] + grid_coords[:, 1] * 10000 + grid_coords[:, 2] * 100000000\n",
    "    \n",
    "    # Select unique points based on grid keys\n",
    "    _, indices = np.unique(keys, return_index=True)\n",
    "    \n",
    "    # Return sampled points\n",
    "    return point_cloud[indices]\n",
    "\n",
    "\n",
    "class CameraInfo():\n",
    "    \"\"\" Camera intrisics for point cloud creation. \"\"\"\n",
    "    def __init__(self, width, height, fx, fy, cx, cy, scale = 1) :\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fx = fx\n",
    "        self.fy = fy\n",
    "        self.cx = cx\n",
    "        self.cy = cy\n",
    "        self.scale = scale\n",
    "        \n",
    "class SingleVisionProcess(Process):\n",
    "    def __init__(self, device, queue,\n",
    "                enable_rgb=True,\n",
    "                enable_depth=False,\n",
    "                enable_pointcloud=False,\n",
    "                sync_mode=0,\n",
    "                num_points=2048,\n",
    "                z_far=0.50,\n",
    "                z_near=0.07,\n",
    "                use_grid_sampling=True,\n",
    "                img_size=224) -> None:\n",
    "        super(SingleVisionProcess, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.device = device\n",
    "\n",
    "        self.enable_rgb = enable_rgb\n",
    "        self.enable_depth = enable_depth\n",
    "        self.enable_pointcloud = enable_pointcloud\n",
    "        self.sync_mode = sync_mode\n",
    "            \n",
    "        self.use_grid_sampling = use_grid_sampling\n",
    "\n",
    "  \n",
    "        self.resize = True\n",
    "        # self.height, self.width = 512, 512\n",
    "        self.height, self.width = img_size, img_size\n",
    "        \n",
    "        # point cloud params\n",
    "        self.z_far = z_far\n",
    "        self.z_near = z_near\n",
    "        self.num_points = num_points\n",
    "   \n",
    "    def get_vision(self):\n",
    "        frame = self.pipeline.wait_for_frames()\n",
    "        if self.enable_depth:\n",
    "            aligned_frames = self.align.process(frame)\n",
    "            # Get aligned frames\n",
    "            color_frame = aligned_frames.get_color_frame()\n",
    "            color_frame = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    \n",
    "            depth_frame = aligned_frames.get_depth_frame()\n",
    "            depth_frame = np.asanyarray(depth_frame.get_data())\n",
    "            \n",
    "            clip_lower =  0.01\n",
    "            clip_high = 1.0\n",
    "            depth_frame = depth_frame.astype(np.float32)\n",
    "            depth_frame *= self.depth_scale\n",
    "            depth_frame[depth_frame < clip_lower] = clip_lower\n",
    "            depth_frame[depth_frame > clip_high] = clip_high\n",
    "            \n",
    "            if self.enable_pointcloud:\n",
    "                # Nx6\n",
    "                point_cloud_frame = self.create_colored_point_cloud(color_frame, depth_frame, \n",
    "                            far=self.z_far, near=self.z_near, num_points=self.num_points)\n",
    "            else:\n",
    "                point_cloud_frame = None\n",
    "        else:\n",
    "            color_frame = frame.get_color_frame()\n",
    "            color_frame = np.asanyarray(color_frame.get_data())\n",
    "            depth_frame = None\n",
    "            point_cloud_frame = None\n",
    "\n",
    "        # print(\"color:\", color_frame.shape)\n",
    "        # print(\"depth:\", depth_frame.shape)\n",
    "        \n",
    "        if self.resize:\n",
    "            if self.enable_rgb:\n",
    "                color_frame = cv2.resize(color_frame, (self.width, self.height), interpolation=cv2.INTER_LINEAR)\n",
    "            if self.enable_depth:\n",
    "                depth_frame = cv2.resize(depth_frame, (self.width, self.height), interpolation=cv2.INTER_LINEAR)\n",
    "        return color_frame, depth_frame, point_cloud_frame\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.pipeline, self.align, self.depth_scale, self.camera_info = init_given_realsense(self.device, \n",
    "                    enable_rgb=self.enable_rgb, enable_depth=self.enable_depth,\n",
    "                    enable_point_cloud=self.enable_pointcloud,\n",
    "                    sync_mode=self.sync_mode)\n",
    "\n",
    "        debug = False\n",
    "        while True:\n",
    "            color_frame, depth_frame, point_cloud_frame = self.get_vision()\n",
    "            # if self.queue.full():\n",
    "            #     self.queue.get_nowait()  # 丢弃最旧的数据\n",
    "            #     self.queue.put_nowait([color_frame, depth_frame, point_cloud_frame])\n",
    "            self.queue.put([color_frame, depth_frame, point_cloud_frame])\n",
    "            # time.sleep(0.05)\n",
    "\n",
    "    def terminate(self) -> None:\n",
    "        # self.pipeline.stop()\n",
    "        return super().terminate()\n",
    "\n",
    "   \n",
    "    def create_colored_point_cloud(self, color, depth, far=1.0, near=0.1, num_points=10000):\n",
    "        assert(depth.shape[0] == color.shape[0] and depth.shape[1] == color.shape[1])\n",
    "    \n",
    "        # Create meshgrid for pixel coordinates\n",
    "        xmap = np.arange(color.shape[1])\n",
    "        ymap = np.arange(color.shape[0])\n",
    "        xmap, ymap = np.meshgrid(xmap, ymap)\n",
    "\n",
    "        # Calculate 3D coordinates\n",
    "        points_z = depth / self.camera_info.scale\n",
    "        points_x = (xmap - self.camera_info.cx) * points_z / self.camera_info.fx\n",
    "        points_y = (ymap - self.camera_info.cy) * points_z / self.camera_info.fy\n",
    "        cloud = np.stack([points_x, points_y, points_z], axis=-1)\n",
    "        cloud = cloud.reshape([-1, 3])\n",
    "        \n",
    "        # Clip points based on depth\n",
    "        mask = (cloud[:, 2] < far) & (cloud[:, 2] > near)\n",
    "        cloud = cloud[mask]\n",
    "        color = color.reshape([-1, 3])\n",
    "        color = color[mask]\n",
    "\n",
    "\n",
    "        colored_cloud = np.hstack([cloud, color.astype(np.float32)])\n",
    "        if self.use_grid_sampling:\n",
    "            colored_cloud = grid_sample_pcd(colored_cloud, grid_size=0.005)\n",
    "        \n",
    "        if num_points > colored_cloud.shape[0]:\n",
    "            num_pad = num_points - colored_cloud.shape[0]\n",
    "            pad_points = np.zeros((num_pad, 6))\n",
    "            colored_cloud = np.concatenate([colored_cloud, pad_points], axis=0)\n",
    "        else: \n",
    "            # Randomly sample points\n",
    "            selected_idx = np.random.choice(colored_cloud.shape[0], num_points, replace=True)\n",
    "            colored_cloud = colored_cloud[selected_idx]\n",
    "        \n",
    "        # shuffle\n",
    "        np.random.shuffle(colored_cloud)\n",
    "        return colored_cloud\n",
    "\n",
    "\n",
    "    \n",
    "class MultiRealSense(object):\n",
    "    def __init__(self, use_front_cam=True, use_right_cam=False,\n",
    "                 front_cam_idx=0, right_cam_idx=1, \n",
    "                 front_num_points=4096, right_num_points=1024,\n",
    "                 front_z_far=1.0, front_z_near=0.1,\n",
    "                 right_z_far=0.5, right_z_near=0.01,\n",
    "                 use_grid_sampling=True,\n",
    "                 img_size=384):\n",
    "\n",
    "        self.devices = get_realsense_id()\n",
    "    \n",
    "        # 队列长度\n",
    "        self.front_queue = Queue(maxsize=50)\n",
    "        self.right_queue = Queue(maxsize=50)\n",
    "\n",
    "      \n",
    "        # 0: f1380328, 1: f1422212\n",
    "\n",
    "        # sync_mode: Use 1 for master, 2 for slave, 0 for default (no sync)\n",
    "\n",
    "        if use_front_cam:\n",
    "            self.front_process = SingleVisionProcess(self.devices[front_cam_idx], self.front_queue,\n",
    "                            enable_rgb=True, enable_depth=True, enable_pointcloud=True, sync_mode=1,\n",
    "                            num_points=front_num_points, z_far=front_z_far, z_near=front_z_near, \n",
    "                            use_grid_sampling=use_grid_sampling, img_size=img_size)\n",
    "        if use_right_cam:\n",
    "            self.right_process = SingleVisionProcess(self.devices[right_cam_idx], self.right_queue,\n",
    "                    enable_rgb=True, enable_depth=True, enable_pointcloud=True, sync_mode=1,\n",
    "                        num_points=right_num_points, z_far=right_z_far, z_near=right_z_near, \n",
    "                        use_grid_sampling=use_grid_sampling,  img_size=img_size)\n",
    "\n",
    "\n",
    "        if use_front_cam:\n",
    "            self.front_process.start()\n",
    "            print(\"front camera start.\")\n",
    "\n",
    "        if use_right_cam:\n",
    "            self.right_process.start()\n",
    "            print(\"right camera start.\")\n",
    "\n",
    "        self.use_front_cam = use_front_cam\n",
    "        self.use_right_cam = use_right_cam\n",
    "        \n",
    "        \n",
    "    def __call__(self):  \n",
    "        cam_dict = {}\n",
    "        if self.use_front_cam:  \n",
    "            front_color, front_depth, front_point_cloud = self.front_queue.get()\n",
    "            cam_dict.update({'color': front_color, 'depth': front_depth, 'point_cloud':front_point_cloud})\n",
    "      \n",
    "        if self.use_right_cam: \n",
    "            right_color, right_depth, right_point_cloud = self.right_queue.get()\n",
    "            cam_dict.update({'right_color': right_color, 'right_depth': right_depth, 'right_point_cloud':right_point_cloud})\n",
    "        print(self.front_queue.qsize())\n",
    "        return cam_dict\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.use_front_cam:\n",
    "            self.front_process.terminate()\n",
    "        if self.use_right_cam:\n",
    "            self.right_process.terminate()\n",
    "\n",
    "\n",
    "    def __del__(self):\n",
    "        self.finalize()\n",
    "\n",
    "camera1 = MultiRealSense(use_front_cam=True, # by default we use single cam. but we also support multi-cam\n",
    "                            front_num_points=4096,\n",
    "                            img_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "consume time: 0.0026237964630126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "corrupted size vs. prev_size\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "start_time1 = time.time()\n",
    "out = camera1()\n",
    "end_time1 = time.time()\n",
    "# print(out)\n",
    "color1 = out[\"color\"]\n",
    "# print(color1)\n",
    "# color1 = color1[..., ::-1]\n",
    "img = Image.fromarray(color1)\n",
    "img.show()\n",
    "print(\"consume time:\", end_time1-start_time1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
